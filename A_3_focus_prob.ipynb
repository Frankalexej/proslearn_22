{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus Probe\n",
    "\n",
    "This notebook trys to see what part this model looks at during prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from model_dataset import ToneDatasetNew as ThisDataset\n",
    "from model_incremental import *\n",
    "from model_dataset import TokenMap\n",
    "from A_3 import configs\n",
    "from paths import *\n",
    "from H_1_models import TwoConvNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam(model, input_tensor, target_layer, target_class):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_in, grad_out):\n",
    "        gradients.append(grad_out[0])\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    hook_b = target_layer.register_backward_hook(backward_hook)\n",
    "    hook_f = target_layer.register_forward_hook(forward_hook)\n",
    "\n",
    "    output = model(input_tensor)\n",
    "    class_score = output[0, target_class]\n",
    "\n",
    "    model.zero_grad()\n",
    "    class_score.backward()\n",
    "\n",
    "    grad = gradients[0].cpu().data.numpy()[0]\n",
    "    act = activations[0].cpu().data.numpy()[0]\n",
    "\n",
    "    hook_b.remove()\n",
    "    hook_f.remove()\n",
    "\n",
    "    weights = np.mean(grad, axis=(1, 2))\n",
    "    cam = np.sum(weights[:, None, None] * act, axis=0)\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam = cam / np.max(cam) if np.max(cam) != 0 else cam\n",
    "\n",
    "    return cam\n",
    "\n",
    "def get_one_batch(dataloader):\n",
    "    dataloader_iter = iter(dataloader)  # Create an iterator\n",
    "    batch = next(dataloader_iter)      # Get the first batch\n",
    "    return batch\n",
    "\n",
    "def grad_cam_visualization(input_tensor, cam, title=\"Grad-CAM Heatmap on Test Input\"): \n",
    "    # Plot the heatmap on the test Mel spectrogram\n",
    "    plt.imshow(input_tensor.squeeze(0).squeeze(0).cpu().numpy(), aspect='auto', cmap='viridis')\n",
    "    plt.imshow(cam, cmap='jet', alpha=0.5, extent=(0, input_tensor.size(-1), 0, input_tensor.size(-2)))\n",
    "    plt.colorbar(label='Importance')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data: target and full\n",
    "pretype = \"l\"\n",
    "posttype = \"f\"\n",
    "train_name = \"A3\"\n",
    "ts = \"1126125730\"\n",
    "model_type = \"twoconvCNN\"\n",
    "pre_epoch = 50\n",
    "total_epoch = 300\n",
    "selection = \"full\"\n",
    "\n",
    "\n",
    "model_save_dir = os.path.join(model_save_, f\"{train_name}-{ts}\")\n",
    "guides_dir = os.path.join(model_save_dir, \"guides\")\n",
    "model_save_dir_specific = os.path.join(model_save_dir, f\"{model_type}-{pre_epoch}-{total_epoch-pre_epoch}\", selection, f\"{pretype}{posttype}\")\n",
    "\n",
    "pool_messanger = PoolMessanger(configs[\"num_dataset\"], configs[\"data_type_mapper\"][pretype], configs[\"data_type_mapper\"][posttype], guides_dir)\n",
    "\n",
    "# NOTE: Subset Cache, this is to manage the reading of datasets. Should be transparent to user. \n",
    "valid_cache = SubsetCache(max_cache_size=configs[\"max_cache_size_valid\"], dataset_class=ThisDataset)\n",
    "full_valid_cache = SubsetCache(max_cache_size=configs[\"max_cache_size_valid\"], dataset_class=ThisDataset)\n",
    "\n",
    "mylist = [\"1\", \"2\", \"3\", \"4\"]\n",
    "mymap = TokenMap(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "# Load Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TwoConvNetwork()\n",
    "model.to(device)\n",
    "\n",
    "model_path = os.path.join(model_save_dir_specific, f\"{epoch}.pt\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 0\n",
    "\n",
    "dataset_id, meta_path, data_path = pool_messanger.get_loading_params(dataset_id,\n",
    "                                                                    eval_type=\"valid\")\n",
    "valid_loader = valid_cache.get_subset(dataset_id, meta_path, data_path, mymap)\n",
    "\n",
    "\n",
    "dataset_id, meta_path, data_path = pool_messanger.get_loading_params(dataset_id,\n",
    "                                                                    eval_type=\"full_valid\")\n",
    "full_valid_loader = full_valid_cache.get_subset(dataset_id, meta_path, data_path, mymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_mel, valid_tag = get_one_batch(valid_loader)\n",
    "full_valid_mel, full_valid_tag = get_one_batch(full_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one randomly\n",
    "random_idx = np.random.randint(0, len(valid_mel))\n",
    "one_valid_mel, one_valid_tag = valid_mel[random_idx].unsqueeze(0), valid_tag[random_idx].item()\n",
    "one_full_valid_mel, one_full_valid_tag = full_valid_mel[random_idx].unsqueeze(0), full_valid_tag[random_idx].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = model.conv[0]    # 4 for the second convolutional layer\n",
    "cam_valid = grad_cam(model, one_valid_mel, target_layer, one_valid_tag)\n",
    "cam_full_valid = grad_cam(model, one_full_valid_mel, target_layer, one_full_valid_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam_visualization(one_valid_mel, cam_valid, title=f\"Grad-CAM Valid {one_valid_tag}\")\n",
    "grad_cam_visualization(one_full_valid_mel, cam_full_valid, title=f\"Grad-CAM Full Valid {one_full_valid_tag}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
